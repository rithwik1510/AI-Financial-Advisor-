<div align="center">

# ğŸ’¸ AI Financial Advisor (Localâ€‘First + OpenAI)

Understand your money, privately. Upload CSV/XLSX statements, get clear analytics and a financial health score, and chat with an AI coach powered by an OpenAIâ€‘compatible API. Your files stay on your machine â€” only a summarized analytics JSON and your question are sent to the LLM.

</div>

## âœ¨ Features

- ğŸ” Local parsing & analytics (CSV/XLSX) â€” no serverâ€‘side storage
- ğŸ“Š Insights: savings rate, DTI, emergency months, discretionary share, anomalies, recurring detection, health score
- ğŸ§® Tools: Mortgage Payment (PITI) & Affordability calculators with assumptions
- ğŸ’¬ Chat: streaming answers using your analytics + tools (OpenAI Chat Completions)
- ğŸ§© Budgets: optional monthly targets and variance table
- âš¡ FastAPI backend + React (Vite + Tailwind) frontend

> Note: PDF document Q&A is disabled in this build. For best results, attach CSV/XLSX exports.

## ğŸ§­ Project Layout

- `backend/` â€” FastAPI API (parse, analyze, ask, tools)
- `frontend/` â€” React + Tailwind UI (uploader, dashboard, chat)
- `analyze_financial_data.py` â€” standalone local CLI analyzer (optional)

## ğŸš€ Quick Start

Backend (Windows PowerShell)
- `backend/run_dev.ps1` â†’ creates venv, installs deps, prompts for `OPENAI_API_KEY`, starts Uvicorn at http://localhost:8000

Backend (manual)
```
cd backend
python -m venv .venv
.venv\Scripts\activate  # or: source .venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

LLM Config (OpenAIâ€‘compatible)
- Required: `OPENAI_API_KEY`
- Optional: `OPENAI_BASE_URL` (default `https://api.openai.com/v1`), `OPENAI_MODEL` (default `gpt-4o-mini`)
- Health checks:
  - `GET /api/health` â†’ `{ status: "ok" }`
  - `GET /api/llm/status` â†’ provider readiness
  - `GET /api/llm/ping` â†’ tiny chat probe (useful for quota/model errors)

Frontend (dev)
```
cd frontend
npm install
npm run dev   # http://localhost:5173
```

## ğŸ› ï¸ API Endpoints (highâ€‘level)

- `POST /api/parse` â€” multipart CSV/XLSX â†’ normalized transactions (PDF ignored)
- `POST /api/analyze` â€” transactions â†’ analytics + health metrics (+ optional budgets)
- `POST /api/ask` â€” analytics + question â†’ LLM answer (OpenAI Chat Completions)
- `POST /api/ask/stream` â€” SSE streaming composition with tools
- `POST /api/tools/{mortgage_payment, affordability}` â€” calculators
- `GET /api/llm/status` â€” provider config check
- `GET /api/llm/ping` â€” minimal completion probe

## ğŸ”’ Privacy

- Parsing and analytics run locally.
- Only the analytics JSON + your question are sent to the LLM.
- No serverâ€‘side persistence; the UI uses localStorage for convenience only.

## ğŸ“¦ CLI Analyzer

```
python analyze_financial_data.py --input <folder> --output analysis.json
```

## ğŸŒ Deploy (Showcase)

Frontend (GitHub Pages) â€” build and publish `frontend/dist` to `gh-pages` (or Netlify/Vercel). The UI expects the API at the same origin; for Pages, set a public API URL and configure axios base URL (or host the backend on Render/Railway and enable CORS for your Pages domain).

Backend (Render/Railway/FlyIO)
- Deploy `backend/` as a Python service (start: `uvicorn app.main:app --host 0.0.0.0 --port 8000`)
- Set env: `OPENAI_API_KEY`, optionally `OPENAI_MODEL`
- Add CORS origin for your frontend domain in `app/main.py` if needed

## ğŸ§‘â€ğŸ’» Tech Stack

- Backend: FastAPI, Pydantic v2, Pandas, Requests
- Frontend: React, Vite, Tailwind
- LLM: OpenAIâ€‘compatible Chat Completions

---

If you use this for a portfolio/demo, consider adding a brief video or screenshots of:
- Upload â†’ Parse â†’ Analyze dashboard
- Tool result cards (PITI/Affordability)
- Chat answering a question using the analytics

Made with care for privacy and clarity. âœ¨

